{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape errors:\n",
    "The inner dimensions must match. Like-----> [3, 2] and [2, 3] \n",
    "\n",
    "Multiplications cannot be executed if [a, b] and [a, b]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29, 10],\n",
       "        [62, 34]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([[1, 3], [4, 6]])\n",
    "b = torch.tensor([[2, 7], [9, 1]])\n",
    "\n",
    "c = torch.matmul(a, b)\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x3 and 2x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[39m=\u001b[39m  torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m9\u001b[39m],\n\u001b[0;32m      2\u001b[0m                   [\u001b[39m2\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m2\u001b[39m],\n\u001b[0;32m      3\u001b[0m                   [\u001b[39m6\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m3\u001b[39m]])\n\u001b[0;32m      4\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m77\u001b[39m],\n\u001b[0;32m      5\u001b[0m                  [\u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m78\u001b[39m]])\n\u001b[1;32m----> 7\u001b[0m z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(x, y)\n\u001b[0;32m      9\u001b[0m z\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x3 and 2x3)"
     ]
    }
   ],
   "source": [
    "x =  torch.tensor([[1, 5, 9],\n",
    "                  [2, 7, 2],\n",
    "                  [6, 9, 3]])\n",
    "y = torch.tensor([[1, 3, 77],\n",
    "                 [2, 5, 78]])\n",
    "\n",
    "z = torch.matmul(x, y)\n",
    "\n",
    "z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this issue we can use the **transpose** of the matrix. Using transpose method we can manipulate the **shape** of the matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[709, 729],\n",
       "        [177, 195],\n",
       "        [264, 291]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = y.T\n",
    "\n",
    "mulT = torch.matmul(x, Y)\n",
    "mulT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding sum, mean, max etc using *rand* values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1163, dtype=torch.float64)\n",
      "tensor(0.9737, dtype=torch.float64)\n",
      "tensor(0.6683, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr1 = np.random.rand(7)\n",
    "arr = torch.tensor(arr1)\n",
    "print(torch.min(arr))\n",
    "print(torch.max(arr))\n",
    "print(torch.mean(arr))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding index of a min, max value in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "print(arr.argmin())\n",
    "print(arr.argmax())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]), torch.Size([9]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1, 10)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5],\n",
       "         [5],\n",
       "         [9],\n",
       "         [2],\n",
       "         [7],\n",
       "         [2],\n",
       "         [6],\n",
       "         [9],\n",
       "         [3]]),\n",
       " torch.Size([9, 1]),\n",
       " tensor([5, 5, 9, 2, 7, 2, 6, 9, 3]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(9, 1)\n",
    "\n",
    "x_reshaped, x_reshaped.shape, x_reshaped.squeeze(), x_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 5, 9, 2, 7, 2, 6, 9, 3]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change view\n",
    "z = x.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5, 5, 9, 2, 7, 2, 6, 9, 3]]),\n",
       " tensor([[5, 5, 9],\n",
       "         [2, 7, 2],\n",
       "         [6, 9, 3]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[5, 5, 9],\n",
       "          [2, 7, 2],\n",
       "          [6, 9, 3]],\n",
       " \n",
       "         [[5, 5, 9],\n",
       "          [2, 7, 2],\n",
       "          [6, 9, 3]],\n",
       " \n",
       "         [[5, 5, 9],\n",
       "          [2, 7, 2],\n",
       "          [6, 9, 3]]]),\n",
       " tensor([[[5, 5, 9],\n",
       "          [5, 5, 9],\n",
       "          [5, 5, 9]],\n",
       " \n",
       "         [[2, 7, 2],\n",
       "          [2, 7, 2],\n",
       "          [2, 7, 2]],\n",
       " \n",
       "         [[6, 9, 3],\n",
       "          [6, 9, 3],\n",
       "          [6, 9, 3]]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x], dim = 0)\n",
    "x_stacked_1 = torch.stack([x, x, x],  dim = 1)\n",
    "x_stacked, x_stacked_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5],\n",
      "        [5],\n",
      "        [9],\n",
      "        [2],\n",
      "        [7],\n",
      "        [2],\n",
      "        [6],\n",
      "        [9],\n",
      "        [3]])\n",
      "Previous tensor shape: torch.Size([9, 1])\n",
      "\n",
      "New tensor: tensor([5, 5, 9, 2, 7, 2, 6, 9, 3])\n",
      "New tensor shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "sq_sh = x_reshaped.squeeze().shape \n",
    "sq = x_reshaped.squeeze()\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous tensor shape: {x_reshaped.shape}\")\n",
    "\n",
    "# After removal of extra dimensions\n",
    "\n",
    "print(f\"\\nNew tensor: {sq}\")\n",
    "print(f\"New tensor shape: {sq_sh}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous targer: tensor([5, 5, 9, 2, 7, 2, 6, 9, 3])\n",
      "Previous shape: torch.Size([9])\n",
      "\n",
      "New tensor: tensor([[5, 5, 9, 2, 7, 2, 6, 9, 3]])\n",
      "New shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze( -adds a single dimension to a target tensor at a specific dimension\n",
    "print(f\"Previous targer: {sq}\")\n",
    "print(f\"Previous shape: {sq_sh}\")\n",
    "\n",
    "# Add an extra dimension with unsqueeze\n",
    "x_unsq = sq.unsqueeze(dim = 0)\n",
    "print(f\"\\nNew tensor: {x_unsq}\")\n",
    "print(f\"New shape: {x_unsq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "#  torch.permute: rearranges the dimensions of a target tensor in a specified order\n",
    "x_org = torch.rand(size=(224, 224, 3)) # [height, width, colour_channels]\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_perm = x_org.permute(2, 0, 1) # shifts axis of x_org, 0 --> 1, 1 --> 2, 2 --> 0\n",
    "\n",
    "print(f\"Previous shape: {x_org.shape}\")\n",
    "print(f\"New shape: {x_perm.shape}\") #[colour_channels, height, width]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10472507.)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_org[0, 0, 0] = torch.randint(1, 20000000, (1,1))\n",
    "\n",
    "x_perm[0,0,0]\n",
    "\n",
    "#torch.randint(1, 20000000, (1,1)) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing(selecting data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1,  2,  3],\n",
       "          [ 4,  5,  6],\n",
       "          [ 7,  8,  9]],\n",
       " \n",
       "         [[10, 11, 12],\n",
       "          [13, 14, 15],\n",
       "          [16, 17, 18]],\n",
       " \n",
       "         [[19, 20, 21],\n",
       "          [22, 23, 24],\n",
       "          [25, 26, 27]]]),\n",
       " torch.Size([3, 3, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor \n",
    "import torch\n",
    "x = torch.arange(1,28).reshape(3,3,3)\n",
    "x, x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on our new tensor\n",
    "x[0]\n",
    "\n",
    "# Index on the middle bracket\n",
    "x[0,0]\n",
    "\n",
    "# Index on the most inner bracket\n",
    "x[1,2,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch tensors & NumPy\n",
    "\n",
    "NumPy is a popular scientific Python numerical computing library.\n",
    "And because of this, PyTorch has functionality to interact with it.\n",
    "* Data in NumPy, want in PyTorch tensor -->     `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -->NumPy --> `torch.Tensor.numpy()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy arrat to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) # warning: when converting from numpy --> pyTorch, pyTorch reflects numpy's default datatype of float64 unless specified otherwise\n",
    "array, tensor\n",
    "\n",
    "array.dtype, tensor.dtype\n",
    "\n",
    "torch.arange(1.0, 8.0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy() # pyTorch's dtype is float32\n",
    "\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
